{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c75a5d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import math\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn import preprocessing as pre\n",
    "\n",
    "import csv\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import statistics\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "426f98cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def XY_hosp(df):\n",
    "    p1=df.hosp_patients.values.tolist()\n",
    "\n",
    "    df2=df.iloc[0:df.shape[0],]\n",
    "    df2['hosp_patients_shift']=p1\n",
    "    \n",
    "\n",
    "    return df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7035e035",
   "metadata": {},
   "outputs": [],
   "source": [
    "def XY_ICU(df):\n",
    "    p1=df.icu_patients.values.tolist()\n",
    "\n",
    "    df2=df.iloc[0:df.shape[0],]\n",
    "    df2['icu_patients_shift']=p1\n",
    "    \n",
    "\n",
    "    return df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bdeb9c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shift_data(df, var, shift_step, timstep):\n",
    "    p1=var[shift_step:].values.tolist()\n",
    "    for i in range(shift_step):\n",
    "        p1.append(0)\n",
    "    #p1.append(0)\n",
    "    #p1.append(0)\n",
    "    #p1.append(0)\n",
    "    #p1.append(0)\n",
    "    \n",
    "    df2=df.iloc[0:df.shape[0],]\n",
    "    df2['shifted_outcomes']=p1\n",
    "    \n",
    "    X_new_hosp=df.iloc[-(shift_step+timstep-1):,:]\n",
    "\n",
    "    return df2,X_new_hosp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6dff05a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to transform the 26 weeks into 6 week per set\n",
    "def create_sw(X_train,Y_train, train_size, model_inputsize,var_num, list1, list2, kernel, c, eps, gamma, test_size):\n",
    " \n",
    "    \n",
    "    X_SVR = []\n",
    "    Y_SVR =[]\n",
    "    #print(len(X_train))\n",
    "    for i in range(train_size):\n",
    "        xset=X_train[i*var_num:i*var_num+var_num*model_inputsize]\n",
    "        X_SVR.append(xset)\n",
    "    \n",
    "    for j in range(train_size):\n",
    "        yset=Y_train[j:j+4]\n",
    "       # print(yset)\n",
    "        Y_SVR.append(yset.ravel())\n",
    "        #print(yset.ravel())\n",
    "    Y_SVR=np.array(Y_SVR)\n",
    "    \n",
    "    X_SVRtrain=X_SVR[0:train_size-1]\n",
    "    X_SVRtest=[X_SVR[train_size-1]]\n",
    "    Y_SVRtrain=Y_SVR[0:train_size-1]\n",
    "    Y_SVRtest=[Y_SVR[train_size- 1]]\n",
    "    #print(X_SVRtest)\n",
    "    #print(Y_SVRtrain)\n",
    "    \n",
    "    test_predictions=swsvr( kernel,c,eps,gamma,X_SVRtrain, Y_SVRtrain, X_SVRtest,  test_size)\n",
    "    return test_predictions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5a553bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def swsvr( kernel, C_best, eps_best, gamma_best, X_SVRtrain, Y_SVRtrain, X_SVRtest,  Xtest_size):\n",
    "    svr = MultiOutputRegressor(SVR(kernel=kernel, C=C_best,epsilon=eps_best, gamma=gamma_best))\n",
    "    #print(Y_SVRtrain)\n",
    "    #print(X_SVRtrain)\n",
    "    #print(len(Y_SVRtrain))\n",
    "    svr.fit(X_SVRtrain,Y_SVRtrain)\n",
    "\n",
    "    predictions = []\n",
    "    for i in range(Xtest_size):\n",
    "        y_pred = svr.predict(X_SVRtest[i].reshape(1,-1))\n",
    "        predictions.append(y_pred)\n",
    "    predictions=np.array(predictions).reshape(-1,1)\n",
    "    return predictions #, contribution_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "61a055f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def traininng_sliding_window(scaler,Xt,Yt, train_size, model_inputsize,forecast_steps, list1, list2, num_var,kernel,C, eps, gamma, X_testsize):\n",
    "\n",
    "    X = []\n",
    "    Y = []\n",
    "    ymean=[]\n",
    "    predictions=[]\n",
    "    for i in range(Xt.shape[0]-train_size-model_inputsize+1):\n",
    "        sc_X=scaler.fit_transform(Xt.iloc[i:i+ train_size+model_inputsize-1,0].values.reshape(-1,1))\n",
    "\n",
    "        for j in range(len(list1)):\n",
    "            sc=scaler.fit_transform(Xt.iloc[i:i + train_size+model_inputsize-1,j+1].values.reshape(-1,1))\n",
    "            sc_X=np.concatenate((sc_X, sc), axis=1)\n",
    "        \n",
    "        for k in range(len(list2)):\n",
    "            sc_X=np.concatenate((sc_X, Xt.iloc[i:i + train_size+model_inputsize-1,k+len(list1)+1].values.reshape(-1,1)), axis=1)\n",
    "        X.append(sc_X.flatten())\n",
    "        #print(len(sc_X.flatten()))\n",
    "        y=Yt.iloc[(i+model_inputsize-1):(i+train_size+model_inputsize+forecast_steps-1-1), 0]\n",
    "        #print(y)\n",
    "        ymean=y.mean()\n",
    "        ysd=y.std()\n",
    "        y_sc=scaler.fit_transform(y.values.reshape(-1,1))\n",
    "        Y.append(y_sc)\n",
    "        #print(sc_X.flatten())\n",
    "        #print(len(sc_X.flatten()))\n",
    "   # for i in range(len(X)):\n",
    "        pred=create_sw(sc_X.flatten(),y_sc,train_size,model_inputsize,num_var, list1, list2, kernel, C, eps, gamma,X_testsize)\n",
    "        predictions_original=pred*ysd+ymean\n",
    "        predictions.append(predictions_original)\n",
    " \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e9d1d5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def rmse(actual, prediction):\n",
    "    rmse_value =sqrt(np.square(np.subtract(actual,prediction)).mean())\n",
    "    return rmse_value\n",
    "\n",
    "def mape(actual,prediction):\n",
    "    mape_value = np.mean(np.abs((actual - prediction)/actual))\n",
    "    return mape_value\n",
    "\n",
    "def MAE_test(actual, prediction):\n",
    "    mae_value=np.mean(np.abs(actual - predictions))\n",
    "    return mae_value"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
